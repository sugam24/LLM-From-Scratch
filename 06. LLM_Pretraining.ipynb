{"cells":[{"cell_type":"markdown","metadata":{"id":"A35Dn1-gJqSm"},"source":["### Calculating the training and validation set losses"]},{"cell_type":"markdown","metadata":{"id":"z7v9w_iVJqSm"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","We use a relatively small dataset for training the LLM (in fact, only one short story)\n","\n","The reasons are:\n","\n","You can run the code examples in a few minutes on a laptop computer without a suitable GPU.\n","\n","The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes.\n","    \n","We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights or bloating the repository size.\n","    \n","For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n","\n","At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately 30 dollars.\n","\n","So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * 30 = 690,000 dollars\n","\n","Below, we use the same dataset we used in chapter 2.\n","\n","</div>"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"OHIp-9S-JqSm","executionInfo":{"status":"ok","timestamp":1769787242059,"user_tz":-345,"elapsed":152,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["import os\n","import urllib.request\n","\n","file_path = \"the-verdict.txt\"\n","url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n","\n","if not os.path.exists(file_path):\n","    with urllib.request.urlopen(url) as response:\n","        text_data = response.read().decode('utf-8')\n","    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","        file.write(text_data)\n","else:\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        text_data = file.read()"]},{"cell_type":"markdown","metadata":{"id":"WYax2Lg_JqSn"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","A quick check that the text loaded ok by printing the first and last 100 words\n","\n","</div>"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9sbNPh66JqSn","outputId":"d0019a14-8d21-4020-c4ee-ab5ab06f3ec4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769787242111,"user_tz":-345,"elapsed":51,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"]}],"source":["# First 100 characters\n","print(text_data[:99])"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"JRnEzyolJqSn","outputId":"8c1fafd4-8b2f-41f2-fb55-062e62d58efd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769787242117,"user_tz":-345,"elapsed":5,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"]}],"source":["# Last 100 characters\n","print(text_data[-99:])"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7KByGI1uJqSo","executionInfo":{"status":"ok","timestamp":1769787243472,"user_tz":-345,"elapsed":1354,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["import tiktoken\n","\n","tokenizer = tiktoken.get_encoding(\"gpt2\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JueZkrCnJqSo","outputId":"f062cead-43d3-497e-8ef1-f2b14cdb0677","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769787243506,"user_tz":-345,"elapsed":30,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Characters: 20479\n","Tokens: 5145\n"]}],"source":["total_characters = len(text_data)\n","total_tokens = len(tokenizer.encode(text_data))\n","\n","print(\"Characters:\", total_characters)\n","print(\"Tokens:\", total_tokens)"]},{"cell_type":"markdown","metadata":{"id":"g98aEP7eJqSo"},"source":["<div class=\"alert alert-block alert-warning\">\n","\n","With 5,145 tokens, the text is very short for training an LLM, but again, it's for educational purposes (we will also load pretrained weights later).\n","\n","Next, we divide the dataset into a training and a validation set and use the data loaders from chapter 2 to prepare the batches for LLM training.\n","    \n","Since we train the LLM to predict the next word in the text, the targets look the same as these inputs, except that the targets are shifted by one position    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"i7lKir-LJqSp"},"source":["### Implementing the DataLoader:\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"lmExl1OZJqSp","executionInfo":{"status":"ok","timestamp":1769787248205,"user_tz":-345,"elapsed":4697,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import tiktoken\n","\n","class GPTDatasetV1(Dataset):\n","    def __init__(self, txt, tokenizer, max_length, stride):\n","        self.input_ids = []\n","        self.target_ids = []\n","\n","        # Tokenize the entire text\n","        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n","\n","        # Use a sliding window to chunk the book into overlapping sequences of max_length\n","        for i in range(0, len(token_ids) - max_length, stride):\n","            input_chunk = token_ids[i:i + max_length]\n","            target_chunk = token_ids[i + 1: i + max_length + 1]\n","            self.input_ids.append(torch.tensor(input_chunk))\n","            self.target_ids.append(torch.tensor(target_chunk))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.target_ids[idx]\n","\n","\n","def create_dataloader_v1(txt, batch_size=4, max_length=256,\n","                         stride=128, shuffle=True, drop_last=True,\n","                         num_workers=0):\n","\n","    # Initialize the tokenizer\n","    tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","    # Create dataset\n","    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n","\n","    # Create dataloader\n","    dataloader = DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        drop_last=drop_last,\n","        num_workers=num_workers\n","    )\n","\n","    return dataloader"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"1N_vqj7WJqSq","executionInfo":{"status":"ok","timestamp":1769787248224,"user_tz":-345,"elapsed":14,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,   # Vocabulary size\n","    \"context_length\": 256, # Shortened context length (orig: 1024)\n","    \"emb_dim\": 768,        # Embedding dimension\n","    \"n_heads\": 12,         # Number of attention heads\n","    \"n_layers\": 12,        # Number of layers\n","    \"drop_rate\": 0.1,      # Dropout rate\n","    \"qkv_bias\": False      # Query-key-value bias\n","}\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"8H6MOH6jJqSq","executionInfo":{"status":"ok","timestamp":1769787248298,"user_tz":-345,"elapsed":68,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["import torch\n","\n","# Train/validation ratio\n","train_ratio = 0.90\n","split_idx = int(train_ratio * len(text_data))\n","train_data = text_data[:split_idx]\n","val_data = text_data[split_idx:]\n","\n","\n","torch.manual_seed(123)\n","\n","train_loader = create_dataloader_v1(\n","    train_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=True,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","val_loader = create_dataloader_v1(\n","    val_data,\n","    batch_size=2,\n","    max_length=GPT_CONFIG_124M[\"context_length\"],\n","    stride=GPT_CONFIG_124M[\"context_length\"],\n","    drop_last=False,\n","    shuffle=False,\n","    num_workers=0\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"OwDzuvX7JqSq","executionInfo":{"status":"ok","timestamp":1769787248317,"user_tz":-345,"elapsed":23,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["# Sanity check\n","\n","if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n","    print(\"Not enough tokens for the training loader. \"\n","          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n","          \"increase the `training_ratio`\")\n","\n","if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n","    print(\"Not enough tokens for the validation loader. \"\n","          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n","          \"decrease the `training_ratio`\")"]},{"cell_type":"markdown","metadata":{"id":"C96L52bgJqSr"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","We use a relatively small batch size to reduce the computational resource demand, and because the dataset is very small to begin with.\n","\n","Llama 2 7B was trained with a batch size of 1024, for example.\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"2_GX7jq2JqSs"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","An optional check that the data was loaded correctly:\n","\n","</div>"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NPdR9xB1JqSz","outputId":"e4b8dd43-ed75-44f8-c3ea-37613af8c608","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769787248401,"user_tz":-345,"elapsed":80,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train loader:\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","\n","Validation loader:\n","torch.Size([2, 256]) torch.Size([2, 256])\n","9\n","1\n"]}],"source":["print(\"Train loader:\")\n","for x, y in train_loader:\n","    print(x.shape, y.shape)\n","\n","print(\"\\nValidation loader:\")\n","for x, y in val_loader:\n","    print(x.shape, y.shape)\n","\n","print(len(train_loader))\n","print(len(val_loader))\n"]},{"cell_type":"markdown","metadata":{"id":"cvEqwdNGJqS3"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","An optional check that the data was loaded correctly:\n","\n","</div>"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"kqfqjfJIJqS5","outputId":"651eae4b-fdee-4d7d-f571-47318756239c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769787248507,"user_tz":-345,"elapsed":104,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training tokens: 4608\n","Validation tokens: 512\n","All tokens: 5120\n"]}],"source":["train_tokens = 0\n","for input_batch, target_batch in train_loader:\n","    train_tokens += input_batch.numel()\n","\n","val_tokens = 0\n","for input_batch, target_batch in val_loader:\n","    val_tokens += input_batch.numel()\n","\n","print(\"Training tokens:\", train_tokens)\n","print(\"Validation tokens:\", val_tokens)\n","print(\"All tokens:\", train_tokens + val_tokens)"]},{"cell_type":"markdown","metadata":{"id":"_AJiSYqoJqS7"},"source":["### Here is the GPT Model class we coded earlier. We will need this"]},{"cell_type":"code","source":["# This block contains the full code of the architecture of GPT-2 model, which we constructed in file 04. LLM_architecture(GPT).ipynb\n","\n","import torch\n","import torch.nn as nn\n","\n","\n","# -------------------------\n","# Configuration\n","# -------------------------\n","GPT_CONFIG_124M = {\n","    \"vocab_size\": 50257,\n","    \"context_length\": 1024,\n","    \"emb_dim\": 768,\n","    \"n_heads\": 12,\n","    \"n_layers\": 12,\n","    \"drop_rate\": 0.1,\n","    \"qkv_bias\": False\n","}\n","\n","\n","# -------------------------\n","# Layer Normalization\n","# -------------------------\n","class LayerNorm(nn.Module):\n","    def __init__(self, emb_dim, eps=1e-5):\n","        super().__init__()\n","        self.eps = eps\n","        self.scale = nn.Parameter(torch.ones(emb_dim))\n","        self.shift = nn.Parameter(torch.zeros(emb_dim))\n","\n","    def forward(self, x):\n","        mean = x.mean(dim=-1, keepdim=True)\n","        var = x.var(dim=-1, keepdim=True, unbiased=False)\n","        return self.scale * (x - mean) / torch.sqrt(var + self.eps) + self.shift\n","\n","\n","# -------------------------\n","# GELU Activation\n","# -------------------------\n","class GELU(nn.Module):\n","    def forward(self, x):\n","        return 0.5 * x * (1 + torch.tanh(\n","            torch.sqrt(torch.tensor(2.0 / torch.pi, device=x.device)) *\n","            (x + 0.044715 * x**3)\n","        ))\n","\n","\n","# -------------------------\n","# Feed Forward Network\n","# -------------------------\n","class FeedForward(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n","            GELU(),\n","            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n","            nn.Dropout(cfg[\"drop_rate\"])\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","# -------------------------\n","# Multi-Head Self-Attention\n","# -------------------------\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        assert cfg[\"emb_dim\"] % cfg[\"n_heads\"] == 0\n","\n","        self.n_heads = cfg[\"n_heads\"]\n","        self.head_dim = cfg[\"emb_dim\"] // cfg[\"n_heads\"]\n","\n","        self.qkv = nn.Linear(\n","            cfg[\"emb_dim\"],\n","            3 * cfg[\"emb_dim\"],\n","            bias=cfg[\"qkv_bias\"]\n","        )\n","        self.proj = nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n","        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        self.register_buffer(\n","            \"mask\",\n","            torch.triu(\n","                torch.ones(cfg[\"context_length\"], cfg[\"context_length\"]),\n","                diagonal=1\n","            )\n","        )\n","\n","    def forward(self, x):\n","        B, T, C = x.shape\n","\n","        qkv = self.qkv(x)\n","        q, k, v = qkv.chunk(3, dim=-1)\n","\n","        q = q.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","        k = k.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","        v = v.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","\n","        att = (q @ k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","        att = att.masked_fill(self.mask[:T, :T].bool(), float(\"-inf\"))\n","        att = self.dropout(torch.softmax(att, dim=-1))\n","\n","        out = att @ v\n","        out = out.transpose(1, 2).contiguous().view(B, T, C)\n","        return self.proj(out)\n","\n","\n","# -------------------------\n","# Transformer Block\n","# -------------------------\n","class TransformerBlock(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.ln1 = LayerNorm(cfg[\"emb_dim\"])\n","        self.attn = MultiHeadAttention(cfg)\n","        self.ln2 = LayerNorm(cfg[\"emb_dim\"])\n","        self.ff = FeedForward(cfg)\n","        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n","\n","    def forward(self, x):\n","        x = x + self.dropout(self.attn(self.ln1(x)))\n","        x = x + self.dropout(self.ff(self.ln2(x)))\n","        return x\n","\n","\n","# -------------------------\n","# GPT Model\n","# -------------------------\n","class GPTModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        self.blocks = nn.Sequential(\n","            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n","        )\n","\n","        self.ln_f = LayerNorm(cfg[\"emb_dim\"])\n","        self.head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n","\n","    def forward(self, idx):\n","        B, T = idx.shape\n","        tok = self.tok_emb(idx)\n","        pos = self.pos_emb(torch.arange(T, device=idx.device))\n","        x = self.drop_emb(tok + pos)\n","        x = self.blocks(x)\n","        x = self.ln_f(x)\n","        return self.head(x)\n"],"metadata":{"id":"t8fGZaLpLUk4","executionInfo":{"status":"ok","timestamp":1769787248512,"user_tz":-345,"elapsed":2,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"5a1jx11vJqS7","executionInfo":{"status":"ok","timestamp":1769787250038,"user_tz":-345,"elapsed":1523,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["class GPTModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        self.trf_blocks = nn.Sequential(\n","            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n","\n","        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n","        self.out_head = nn.Linear(\n","            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n","        )\n","\n","    def forward(self, in_idx):\n","        batch_size, seq_len = in_idx.shape\n","        tok_embeds = self.tok_emb(in_idx)\n","        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n","        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_emb(x)\n","        x = self.trf_blocks(x)\n","        x = self.final_norm(x)\n","        logits = self.out_head(x)\n","        return logits\n","\n","torch.manual_seed(123)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.eval();  # Disable dropout during inference"]},{"cell_type":"markdown","metadata":{"id":"ZpaV3IWTJqS8"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","Next, we implement a utility function to calculate the cross-entropy loss of a given batch.\n","\n","In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader.\n","</div>"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"sPtPNil1JqS8","executionInfo":{"status":"ok","timestamp":1769787250043,"user_tz":-345,"elapsed":2,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["def calc_loss_batch(input_batch, target_batch, model, device):\n","    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n","    logits = model(input_batch)\n","    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n","    return loss\n","\n","\n","def calc_loss_loader(data_loader, model, device, num_batches=None):\n","    total_loss = 0.\n","    if len(data_loader) == 0:\n","        return float(\"nan\")\n","    elif num_batches is None:\n","        num_batches = len(data_loader)\n","    else:\n","        # Reduce the number of batches to match the total number of batches in the data loader\n","        # if num_batches exceeds the number of batches in the data loader\n","        num_batches = min(num_batches, len(data_loader))\n","    for i, (input_batch, target_batch) in enumerate(data_loader):\n","        if i < num_batches:\n","            loss = calc_loss_batch(input_batch, target_batch, model, device)\n","            total_loss += loss.item()\n","        else:\n","            break\n","    return total_loss / num_batches"]},{"cell_type":"markdown","metadata":{"id":"Mjfp-SO0JqS9"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code.\n","    \n","Via the device setting, we ensure that the data is loaded onto the same device as the LLM model.\n","    \n","</div>"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Af-XmgG9JqS9","outputId":"35094175-fb76-4761-e4b6-835ff06f3bf2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769787274190,"user_tz":-345,"elapsed":24146,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training loss: 10.988502078586155\n","Validation loss: 10.99034309387207\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Note:\n","# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n","# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n","# However, the resulting loss values may be slightly different.\n","\n","#if torch.cuda.is_available():\n","#    device = torch.device(\"cuda\")\n","#elif torch.backends.mps.is_available():\n","#    device = torch.device(\"mps\")\n","#else:\n","#    device = torch.device(\"cpu\")\n","#\n","# print(f\"Using {device} device.\")\n","\n","\n","model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n","\n","\n","torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n","\n","with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n","    train_loss = calc_loss_loader(train_loader, model, device)\n","    val_loss = calc_loss_loader(val_loader, model, device)\n","\n","print(\"Training loss:\", train_loss)\n","print(\"Validation loss:\", val_loss)"]},{"cell_type":"markdown","metadata":{"id":"E-CHbIWZJqS9"},"source":["## TRAINING LOOP FOR THE LLM"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Z4wQvkYOJqS9","executionInfo":{"status":"ok","timestamp":1769787274201,"user_tz":-345,"elapsed":9,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n","                       eval_freq, eval_iter, start_context, tokenizer):\n","    # Initialize lists to track losses and tokens seen\n","    train_losses, val_losses, track_tokens_seen = [], [], []\n","    tokens_seen, global_step = 0, -1\n","\n","    # Main training loop\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","\n","        for input_batch, target_batch in train_loader:\n","            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n","            loss = calc_loss_batch(input_batch, target_batch, model, device)\n","            loss.backward() # Calculate loss gradients\n","            optimizer.step() # Update model weights using loss gradients\n","            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n","            global_step += 1\n","\n","            # Optional evaluation step\n","            if global_step % eval_freq == 0:\n","                train_loss, val_loss = evaluate_model(\n","                    model, train_loader, val_loader, device, eval_iter)\n","                train_losses.append(train_loss)\n","                val_losses.append(val_loss)\n","                track_tokens_seen.append(tokens_seen)\n","                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n","\n","        # Print a sample text after each epoch\n","        generate_and_print_sample(\n","            model, tokenizer, device, start_context\n","        )\n","\n","    return train_losses, val_losses, track_tokens_seen"]},{"cell_type":"markdown","metadata":{"id":"Bpb0zqqXJqS-"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","Step 1: Initialize lists to track losses and tokens seen\n","\n","Step 2: Start the main training loop\n","\n","Step 3: Reset loss gradients from previous batch iteration\n","\n","Step 4: Calculate loss gradients\n","\n","Step 5: Update model weights using loss gradients\n","\n","Step 6: Optional evaluation step\n","\n","Step 7: Print a sample text after each epoch\n","    \n","</div>"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"g4aOTMxWJqS-","executionInfo":{"status":"ok","timestamp":1769787274202,"user_tz":-345,"elapsed":9,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n","    model.eval()\n","    with torch.no_grad():\n","        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n","        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n","    model.train()\n","    return train_loss, val_loss"]},{"cell_type":"markdown","metadata":{"id":"LwzIZsYBJqS-"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","The evaluate_model function calculates the loss over the training and\n","validation set while ensuring the model is in evaluation mode with gradient tracking and\n","dropout disabled when calculating the loss over the training and validation sets\n","    \n","</div>"]},{"cell_type":"code","source":["def generate_text_simple(model, idx, max_new_tokens, context_size):\n","    for _ in range(max_new_tokens):\n","\n","        # Crop context if it exceeds model limit\n","        idx_cond = idx[:, -context_size:]\n","\n","        # Forward pass\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","\n","        # Use last token logits\n","        logits = logits[:, -1, :]\n","\n","        # Convert to probabilities\n","        probs = torch.softmax(logits, dim=-1)\n","\n","        # Greedy decoding\n","        idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n","\n","        # Append token\n","        idx = torch.cat((idx, idx_next), dim=1)\n","\n","    return idx\n"],"metadata":{"id":"wAjfpFDCTZlC","executionInfo":{"status":"ok","timestamp":1769787274202,"user_tz":-345,"elapsed":6,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import tiktoken\n","\n","def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n","    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n","    return encoded_tensor\n","\n","def token_ids_to_text(token_ids, tokenizer):\n","    flat = token_ids.squeeze(0) # remove batch dimension\n","    return tokenizer.decode(flat.tolist())\n","\n","start_context = \"Every effort moves you\"\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","token_ids = generate_text_simple(\n","    model=model,\n","    idx=text_to_token_ids(start_context, tokenizer),\n","    max_new_tokens=10,\n","    context_size=GPT_CONFIG_124M[\"context_length\"]\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAZS__SKTMmA","executionInfo":{"status":"ok","timestamp":1769787275444,"user_tz":-345,"elapsed":1246,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"8d1623cb-8371-4749-bbaf-6769d58985fd"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Output text:\n"," Every effort moves you Aeiman Byeswickattributeometer inspector Normandy freezerigrate\n"]}]},{"cell_type":"code","execution_count":20,"metadata":{"id":"4kMgSVzEJqS-","executionInfo":{"status":"ok","timestamp":1769787275451,"user_tz":-345,"elapsed":6,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["def generate_and_print_sample(model, tokenizer, device, start_context):\n","    model.eval()\n","    context_size = model.pos_emb.weight.shape[0]\n","    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n","    with torch.no_grad():\n","        token_ids = generate_text_simple(\n","            model=model, idx=encoded,\n","            max_new_tokens=50, context_size=context_size\n","        )\n","    decoded_text = token_ids_to_text(token_ids, tokenizer)\n","    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n","    model.train()"]},{"cell_type":"markdown","metadata":{"id":"zfROVexiJqS-"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","The generate_and_print_sample function is a convenience function that we use to track whether the model improves during the training.\n","\n","In particular, the generate_and_print_sample function takes a text snippet (start_context) as input,\n","converts it into token IDs, and feeds it to the LLM to generate a text sample using the\n","generate_text_simple function we used earlier\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"scPqSXqOJqS_"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","Let's see this all in action by training a GPTModel instance for 10 epochs using an AdamW\n","optimizer and the train_model_simple function we defined earlier.\n","</div>"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"xYJRmliMJqS_","outputId":"1eb2267f-76f6-4c23-bd25-c6fe3432f605","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769788325963,"user_tz":-345,"elapsed":1050509,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ep 1 (Step 000000): Train loss 9.915, Val loss 10.026\n","Ep 1 (Step 000005): Train loss 8.061, Val loss 8.379\n","Every effort moves you.                                                 \n","Ep 2 (Step 000010): Train loss 6.767, Val loss 7.056\n","Ep 2 (Step 000015): Train loss 6.095, Val loss 6.586\n","Every effort moves you, the, the, the, the.                                         \n","Ep 3 (Step 000020): Train loss 5.311, Val loss 6.455\n","Ep 3 (Step 000025): Train loss 5.510, Val loss 6.447\n","Every effort moves you hadburn had--as. Gisburn------ a---- a. Gisburn, and the of the of the of theburn, and the had to the had the-- to the of the of the of the of the of\n","Ep 4 (Step 000030): Train loss 5.051, Val loss 6.388\n","Ep 4 (Step 000035): Train loss 4.710, Val loss 6.248\n","Every effort moves you. \"I had been a--I him, and I had been a. Gisburn, and my \"I had been. Gisburn's a to the his he had been. Gisburn--I had been the first\n","Ep 5 (Step 000040): Train loss 4.327, Val loss 6.256\n","Every effort moves you know the last--I                       \" the his he was the donkey, the donkey.           \n","Ep 6 (Step 000045): Train loss 4.037, Val loss 6.178\n","Ep 6 (Step 000050): Train loss 3.478, Val loss 6.105\n","Every effort moves you know that, and a little a little was the his pictures.                                     \n","Ep 7 (Step 000055): Train loss 3.076, Val loss 6.154\n","Ep 7 (Step 000060): Train loss 2.539, Val loss 6.196\n","Every effort moves you know; and my-stream stroke.  \"--as such--I.        \"Oh, and he was his pictures.  \"--and it, the donkey. \"Oh, I had\n","Ep 8 (Step 000065): Train loss 2.282, Val loss 6.200\n","Ep 8 (Step 000070): Train loss 1.775, Val loss 6.224\n","Every effort moves you?\"  \"Yes--quite ins it to the fact the donkey. \"I was no I felt to me. \"I moved away, and I looked at the donkey again. I saw that, and my dear, and I had\n","Ep 9 (Step 000075): Train loss 1.554, Val loss 6.238\n","Ep 9 (Step 000080): Train loss 1.139, Val loss 6.256\n","Every effort moves you?\"  \"Yes--quite insensible to the irony.   \"Oh, when I looked up, I had the man of the moment--as Jack himself, I had the sketch of the donkey. \"There were days when I\n","Ep 10 (Step 000085): Train loss 0.943, Val loss 6.316\n","Every effort moves you?\"  \"Yes--quite insensible to the irony.  \"Oh, when I was, in fact, and he _ a smile behind his close grayish beard--as if he had the donkey. \"--that I found\n","Training completed in 17.51 minutes.\n"]}],"source":["# Note:\n","# Uncomment the following code to calculate the execution time\n","import time\n","start_time = time.time()\n","\n","torch.manual_seed(123)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n","\n","num_epochs = 10\n","train_losses, val_losses, tokens_seen = train_model_simple(\n","    model, train_loader, val_loader, optimizer, device,\n","    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n","    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",")\n","\n","# Note:\n","# Uncomment the following code to show the execution time\n","end_time = time.time()\n","execution_time_minutes = (end_time - start_time) / 60\n","print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"]},{"cell_type":"markdown","metadata":{"id":"xQtM7fZ5JqS_"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","As we can see, based on the results printed during the training, the training loss improves\n","drastically, starting with a value of 9.781 and converging to 0.391.\n","\n","The language skills of\n","the model have improved quite a lot. In the beginning, the model is only able to append\n","commas to the start context (\"Every effort moves you,,,,,,,,,,,,\") or repeat the\n","word \"and\".\n","\n","At the end of the training, it can generate grammatically correct text.\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"lYkZYOVjJqS_"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","Similar to the training set loss, we can see that the validation loss starts high (9.856)\n","and decreases during the training.\n","\n","However, it never becomes as small as the training set\n","loss and remains at 6.372 after the 10th epoch.\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"9a8WIZF2JqS_"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","Let's create a simple plot that shows the training and validation set losses side by side\n","</div>"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ZCPAP_ZoJqS_","executionInfo":{"status":"ok","timestamp":1769788327429,"user_tz":-345,"elapsed":1462,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"colab":{"base_uri":"https://localhost:8080/","height":307},"outputId":"0d1d4fa7-57ff-4269-c11c-df72d6f894d9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 500x300 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","from matplotlib.ticker import MaxNLocator\n","\n","\n","def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n","    fig, ax1 = plt.subplots(figsize=(5, 3))\n","\n","    # Plot training and validation loss against epochs\n","    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n","    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n","    ax1.set_xlabel(\"Epochs\")\n","    ax1.set_ylabel(\"Loss\")\n","    ax1.legend(loc=\"upper right\")\n","    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n","\n","    # Create a second x-axis for tokens seen\n","    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n","    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n","    ax2.set_xlabel(\"Tokens seen\")\n","\n","    fig.tight_layout()  # Adjust layout to make room\n","    plt.savefig(\"loss-plot.pdf\")\n","    plt.show()\n","\n","epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n","plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"]},{"cell_type":"markdown","metadata":{"id":"9eNT_E29JqTA"},"source":["<div class=\"alert alert-block alert-warning\">\n","\n","Both the training and validation losses start to improve for the first\n","epoch. However, the losses start to diverge past the second epoch.\n","\n","This divergence and the\n","fact that the validation loss is much larger than the training loss indicate that the model is\n","overfitting to the training data.\n","\n","We can confirm that the model memorizes the training data\n","verbatim by searching for the generated text snippets, such as \"quite insensible to the\n","irony\" in the \"The Verdict\" text file.\n","\n","\n","This memorization is expected since we are working with a very, very small training\n","dataset and training the model for multiple epochs.\n","\n","Usually, it's common to train a model\n","on a much, much larger dataset for only one epoch.   \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"F4SmX5vnJqTA"},"source":["## DECODING STRATEGIES TO CONTROL RANDOMNESS"]},{"cell_type":"markdown","metadata":{"id":"LX55EJD2JqTA"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","First, we briefly revisit the generate_text_simple function\n","from the previous chapter that we used inside the generate_and_print_sample earlier in\n","this chapter.\n","\n","Then, we will cover two techniques, temperature scaling, and top-k sampling,\n","to improve this function.\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"-uQXpxNxJqTA"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","We begin by transferring the model back from the GPU to the CPU since inference with a\n","relatively small model does not require a GPU. Also, after training, we put the model into\n","evaluation model to turn off random components such as dropout:\n","</div>"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"33oN5XqyJqTA","executionInfo":{"status":"ok","timestamp":1769788327442,"user_tz":-345,"elapsed":11,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b303ec9-62e2-4e2f-f298-ae844a39109d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (tok_emb): Embedding(50257, 768)\n","  (pos_emb): Embedding(1024, 768)\n","  (drop_emb): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): MultiHeadAttention(\n","        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln2): LayerNorm()\n","      (ff): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":23}],"source":["model.to(\"cpu\")\n","model.eval()"]},{"cell_type":"markdown","metadata":{"id":"Wao8UbQ-JqTB"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","Next, we plug the GPTModel instance (model) into the generate_text_simple function,\n","which uses the LLM to generate one token at a time:\n","</div>"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"gU50acPQJqTB","executionInfo":{"status":"ok","timestamp":1769788332387,"user_tz":-345,"elapsed":4944,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19aa130a-19fc-4c07-c023-5d4affa13dbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Output text:\n"," Every effort moves you?\"\n","\n","\"Yes--quite insensible to the irony.\n","\n","\"Oh, when I was, in fact,\n"]}],"source":["tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","token_ids = generate_text_simple(\n","    model=model,\n","    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n","    max_new_tokens=25,\n","    context_size=GPT_CONFIG_124M[\"context_length\"]\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"]},{"cell_type":"markdown","metadata":{"id":"uc2ndEr3JqTB"},"source":["### DECODING STRATEGY 1: TEMPERATURE SCALING\n","\n","> Add blockquote\n","\n"]},{"cell_type":"markdown","metadata":{"id":"boGaftcxJqTB"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","Previously, inside the generate_text_simple function, we always sampled the token\n","with the highest probability as the next token using torch.argmax, also known as greedy\n","decoding.\n","\n","To generate text with more variety, we can replace the argmax with a function\n","that samples from a probability distribution (here, the probability scores the LLM generates\n","for each vocabulary entry at each token generation step).\n","\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"AKcoXSOAJqTB"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","To illustrate the probabilistic sampling with a concrete example, let's briefly discuss the\n","next-token generation process using a very small vocabulary for illustration purposes:\n","\n","</div>"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"N8ujoXe9JqTB","executionInfo":{"status":"ok","timestamp":1769788332393,"user_tz":-345,"elapsed":4,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["vocab = {\n","    \"closer\": 0,\n","    \"every\": 1,\n","    \"effort\": 2,\n","    \"forward\": 3,\n","    \"inches\": 4,\n","    \"moves\": 5,\n","    \"pizza\": 6,\n","    \"toward\": 7,\n","    \"you\": 8,\n","}\n","\n","inverse_vocab = {v: k for k, v in vocab.items()}"]},{"cell_type":"markdown","metadata":{"id":"4gcRctFkJqTC"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","Next, assume the LLM is given the start context \"every effort moves you\" and\n","generates the following next-token logits:\n","\n","</div>"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ls7P7bh5JqTC","executionInfo":{"status":"ok","timestamp":1769788332400,"user_tz":-345,"elapsed":5,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["next_token_logits = torch.tensor(\n","[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",")"]},{"cell_type":"code","source":["# This is example of low temperature(T = 0.1)\n","next_token_logits2 = next_token_logits/0.1\n","print(torch.softmax(next_token_logits2, dim = 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SY6dWOZigvSP","executionInfo":{"status":"ok","timestamp":1769788332425,"user_tz":-345,"elapsed":26,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"78816ab7-dd4d-4c1e-f5cb-e4264f8a45ae"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n","        2.9718e-38, 9.0133e-03, 2.8514e-22])\n"]}]},{"cell_type":"code","source":["# This is example of high temperature(T = 5)\n","next_token_logits2 = next_token_logits/5\n","print(torch.softmax(next_token_logits2, dim = 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-whV_RlhLDn","executionInfo":{"status":"ok","timestamp":1769788332508,"user_tz":-345,"elapsed":79,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"2852a202-f409-4117-dff9-1de96b848c83"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"]}]},{"cell_type":"markdown","metadata":{"id":"pDHbYgkQJqTC"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","As discussed in the previous chapter, inside the generate_text_simple, we convert the\n","logits into probabilities via the softmax function and obtain the token ID corresponding the\n","generated token via the argmax function, which we can then map back into text via the\n","inverse vocabulary:\n","\n","</div>"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"6r09BIA_JqTC","executionInfo":{"status":"ok","timestamp":1769788332508,"user_tz":-345,"elapsed":15,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b9933bf-fda8-43a4-96b1-4239693ba294"},"outputs":[{"output_type":"stream","name":"stdout","text":["forward\n"]}],"source":["probas = torch.softmax(next_token_logits, dim=0)\n","next_token_id = torch.argmax(probas).item()\n","print(inverse_vocab[next_token_id])"]},{"cell_type":"markdown","metadata":{"id":"fUfof0zRJqTC"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","To implement a probabilistic sampling process, we can now replace the argmax with the\n","multinomial function in PyTorch:\n","\n","</div>"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"naUfua8hJqTC","executionInfo":{"status":"ok","timestamp":1769788332509,"user_tz":-345,"elapsed":9,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"793858e3-0ad3-43f2-a2c7-235d754ae823"},"outputs":[{"output_type":"stream","name":"stdout","text":["forward\n"]}],"source":["torch.manual_seed(123)\n","next_token_id = torch.multinomial(probas, num_samples=1).item()\n","print(inverse_vocab[next_token_id])"]},{"cell_type":"markdown","metadata":{"id":"cLL7xkkBJqTD"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","The printed output is \"forward\" just like before. What happened? The multinomial\n","function samples the next token proportional to its probability score.\n","\n","In other words,\n","\"forward\" is still the most likely token and will be selected by multinomial most of the\n","time but not all the time.\n","\n","To illustrate this, let's implement a function that repeats this\n","sampling 1000 times:\n","\n","</div>"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"z7MwUuQiJqTD","executionInfo":{"status":"ok","timestamp":1769788332523,"user_tz":-345,"elapsed":12,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aab727c4-2993-40bd-e012-77415a005a26"},"outputs":[{"output_type":"stream","name":"stdout","text":["73 x closer\n","0 x every\n","0 x effort\n","582 x forward\n","2 x inches\n","0 x moves\n","0 x pizza\n","343 x toward\n"]}],"source":["def print_sampled_tokens(probas):\n","    torch.manual_seed(123) # Manual seed for reproducibility\n","    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n","    sampled_ids = torch.bincount(torch.tensor(sample))\n","    for i, freq in enumerate(sampled_ids):\n","        print(f\"{freq} x {inverse_vocab[i]}\")\n","\n","print_sampled_tokens(probas)"]},{"cell_type":"markdown","metadata":{"id":"-0w6zFVRJqTD"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","As we can see based on the output, the word \"forward\" is sampled most of the time (582\n","out of 1000 times), but other tokens such as \"closer\", \"inches\", and \"toward\" will also\n","be sampled some of the time.\n","\n","This means that if we replaced the argmax function with the\n","multinomial function inside the generate_and_print_sample function, the LLM would\n","sometimes generate texts such as \"every effort moves you toward\", \"every effort\n","moves you inches\", and \"every effort moves you closer\" instead of \"every effort\n","moves you forward\".\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"Nd8GtCDMJqTE"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","We can further control the distribution and selection process via a concept called\n","temperature scaling, where temperature scaling is just a fancy description for dividing the\n","logits by a number greater than 0:\n","\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"FfG7ZprSJqTE"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","Temperatures greater than 1 result in more uniformly distributed token probabilities,\n","and Temperatures smaller than 1 will result in more confident (sharper or more peaky)\n","distributions.\n","\n","Let's illustrate this by plotting the original probabilities alongside\n","probabilities scaled with different temperature values:\n","\n","</div>"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"4LDlI0y8JqTE","executionInfo":{"status":"ok","timestamp":1769788332529,"user_tz":-345,"elapsed":4,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"outputs":[],"source":["def softmax_with_temperature(logits, temperature):\n","    scaled_logits = logits / temperature\n","    return torch.softmax(scaled_logits, dim=0)\n","\n","# Temperature values\n","temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n","\n","# Calculate scaled probabilities\n","scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"]},{"cell_type":"code","source":["print(scaled_probas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fow2E0F_efiZ","executionInfo":{"status":"ok","timestamp":1769788332544,"user_tz":-345,"elapsed":13,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"984eba60-6ede-49fd-be26-57927c32976b"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n","        1.0120e-04, 3.5758e-01, 4.0122e-03]), tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n","        2.9718e-38, 9.0133e-03, 2.8514e-22]), tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])]\n"]}]},{"cell_type":"code","execution_count":34,"metadata":{"id":"WRkdVhHeJqTE","executionInfo":{"status":"ok","timestamp":1769788332962,"user_tz":-345,"elapsed":416,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"colab":{"base_uri":"https://localhost:8080/","height":307},"outputId":"006825ef-11af-4256-c46d-e7d2d6c9c9c9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 500x300 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Plotting\n","x = torch.arange(len(vocab))\n","bar_width = 0.15\n","\n","fig, ax = plt.subplots(figsize=(5, 3))\n","for i, T in enumerate(temperatures):\n","    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n","\n","ax.set_ylabel('Probability')\n","ax.set_xticks(x)\n","ax.set_xticklabels(vocab.keys(), rotation=90)\n","ax.legend()\n","\n","plt.tight_layout()\n","plt.savefig(\"temperature-plot.pdf\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kiGF_2p5JqTE"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","A temperature of 1 divides the logits by 1 before passing them to the softmax function to\n","compute the probability scores.\n","\n","In other words, using a temperature of 1 is the same as not\n","using any temperature scaling.\n","\n","In this case, the tokens are selected with a probability equal\n","to the original softmax probability scores via the multinomial sampling function in PyTorch.    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"zBossvnsJqTF"},"source":["<div class=\"alert alert-block alert-info\">\n","\n","Applying very small temperatures, such as 0.1, will\n","result in sharper distributions such that the behavior of the multinomial function selects\n","the most likely token (here: \"forward\") almost 100% of the time, approaching the\n","behavior of the argmax function.\n","\n","Vice versa, a temperature of 5 results in a more uniform\n","distribution where other tokens are selected more often.\n","\n","This can add more variety to the\n","generated texts but also more often results in nonsensical text.\n","\n","For example, using the\n","temperature of 5 results in texts such as \"every effort moves you pizza\" about 4% of\n","the time.\n","    \n","</div>"]},{"cell_type":"markdown","source":["### DECODING STRATEGY 2: Top-k Sampling\n"],"metadata":{"id":"uiR_ZYKFfnZG"}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","In the previous section, we implemented a probabilistic sampling approach coupled with\n","temperature scaling to increase the diversity of the outputs.\n","\n","We saw that higher\n","temperature values result in more uniformly distributed next-token probabilities, which\n","result in more diverse outputs as it reduces the likelihood of the model repeatedly selecting\n","the most probable token.\n","\n","This method allows for exploring less likely but potentially more\n","interesting and creative paths in the generation process.\n","\n","However, One downside of this\n","approach is that it sometimes leads to grammatically incorrect or completely nonsensical\n","outputs such as \"every effort moves you pizza\".\n","</div>"],"metadata":{"id":"j1GFlhzofzoK"}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","1.   List item\n","2.   List item\n","\n","\n","\n","In this section, we introduce another concept called top-k sampling, which, when\n","combined with probabilistic sampling and temperature scaling, can improve the text\n","generation results.\n","\n","In top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens\n","and exclude all other tokens from the selection process by masking their probability scores.\n","    \n","</div>"],"metadata":{"id":"oUFryQfbf2km"}},{"cell_type":"code","source":["top_k = 3\n","top_logits, top_pos = torch.topk(next_token_logits, top_k)\n","print(\"Top logits:\", top_logits)\n","print(\"Top positions:\", top_pos)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwzAnX1uf7Zp","executionInfo":{"status":"ok","timestamp":1769788332996,"user_tz":-345,"elapsed":33,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"3847cc50-f048-4e79-f5c0-6752bf308124"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Top logits: tensor([6.7500, 6.2800, 4.5100])\n","Top positions: tensor([3, 7, 0])\n"]}]},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","1.   *List item*\n","2.   List item\n","\n","\n","\n","Subsequently, we apply PyTorch's where function to set the logit values of tokens that are\n","below the lowest logit value within our top-3 selection to negative infinity (-inf).\n","    \n","</div>"],"metadata":{"id":"koxgpCYhf6YH"}},{"cell_type":"code","source":["new_logits = torch.where(\n","    condition=next_token_logits < top_logits[-1],\n","    input=torch.tensor(float(\"-inf\")),\n","    other=next_token_logits\n",")\n","\n","print(new_logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoX8YecsgGLy","executionInfo":{"status":"ok","timestamp":1769788333001,"user_tz":-345,"elapsed":10,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"378ac1c4-24da-4d67-ea15-bd998774c29c"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"]}]},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","1.   List item\n","2.   List item\n","\n","\n","\n","Lastly, let's apply the softmax function to turn these into next-token probabilities:\n","    \n","\n","---\n","\n","\n","</div>"],"metadata":{"id":"U1Zn9S40gLHN"}},{"cell_type":"code","source":["topk_probas = torch.softmax(new_logits, dim=0)\n","print(topk_probas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hpa6QYZlgMD7","executionInfo":{"status":"ok","timestamp":1769788333008,"user_tz":-345,"elapsed":5,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"06424115-d1ab-4a77-aab3-dddc4dd066a0"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"]}]},{"cell_type":"markdown","source":["### Merge Temperature Scaling and Top-k sampling"],"metadata":{"id":"mkOPpcabgOkX"}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","We can now apply the temperature scaling and multinomial function for probabilistic\n","sampling introduced in the previous section to select the next token among these 3 nonzero probability scores to generate the next token. We do this in the next section by\n","modifying the text generation function.\n","\n","</div>"],"metadata":{"id":"2Av4PAwwgRae"}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","The previous two subsections introduced two concepts to increase the diversity of LLMgenerated text: temperature sampling and top-k sampling. In this section, we combine and\n","add these concepts to modify the generate_simple function we used to generate text via\n","the LLM earlier, creating a new generate function:\n","\n","</div>"],"metadata":{"id":"G2Dg5q5wgVEq"}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-info\">\n","\n","Step 1: For-loop is the same as before: Get logits, and only focus on last time step\n","\n","Step 2: In this new section, we filter logits with top_k sampling\n","\n","Step 3: This is the new section where we apply temperature scaling\n","    \n","Step 4: Carry out greedy next-token selection as before when temperature scaling is disabled\n","\n","Step 5: Stop generating early if end-of-sequence token is encountered and eos_id is specified\n","\n","</div>"],"metadata":{"id":"mxyjA5gtgY1X"}},{"cell_type":"code","source":["def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n","\n","    # For-loop is the same as before: Get logits, and only focus on last time step\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_size:]\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]\n","\n","        # New: Filter logits with top_k sampling\n","        if top_k is not None:\n","            # Keep only top_k values\n","            top_logits, _ = torch.topk(logits, top_k)\n","            min_val = top_logits[:, -1]\n","            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n","\n","        # New: Apply temperature scaling\n","        if temperature > 0.0:\n","            logits = logits / temperature\n","\n","            # Apply softmax to get probabilities\n","            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n","\n","            # Sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n","\n","        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n","        else:\n","            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n","\n","        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n","            break\n","\n","        # Same as before: append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n","\n","    return idx"],"metadata":{"id":"yjeoSN5igbID","executionInfo":{"status":"ok","timestamp":1769788333018,"user_tz":-345,"elapsed":8,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","---\n","\n","\n","\n","Let's now see this new generate function in action:\n","</div>"],"metadata":{"id":"UsSVPDzUgfur"}},{"cell_type":"code","source":["torch.manual_seed(123)\n","\n","token_ids = generate(\n","    model=model,\n","    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n","    max_new_tokens=15,\n","    context_size=GPT_CONFIG_124M[\"context_length\"],\n","    top_k=25,\n","    temperature=1.4\n",")\n","\n","print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hp5ppibzgiGZ","executionInfo":{"status":"ok","timestamp":1769788335578,"user_tz":-345,"elapsed":2559,"user":{"displayName":"Sugam Dahal","userId":"12886190372199512207"}},"outputId":"35e18148-4623-41ac-bead-340588a02455"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Output text:\n"," Every effort moves youlit,\" was down surprise. Th. Gisitely told by his head\n"]}]},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","\n","As we can see, the generated text is very different from the one we previously generated\n","via the generate_simple function at the beginning of section 5.3 (\"Every effort moves\n","you know,\" was one of the axioms he laid...!\"), which was a memorized passage\n","from the training set.\n","\n","</div>"],"metadata":{"id":"lBGEYKI3gkwg"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[{"file_id":"1p87nemE6wFjGhkX4kC7KfGv1juMZJrMr","timestamp":1769613074260}]}},"nbformat":4,"nbformat_minor":0}