{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9d65f4",
   "metadata": {},
   "source": [
    "# üìö Understanding GPT-2 Model Weights & Files\n",
    "\n",
    "This notebook provides a comprehensive guide to understanding the GPT-2 model files, how they are structured, downloaded, and used in practice.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d669aad",
   "metadata": {},
   "source": [
    "## üìÅ Overview of GPT-2 Model Files\n",
    "\n",
    "When you download GPT-2 weights from OpenAI, you get the following files in the `gpt2/124M/` directory:\n",
    "\n",
    "| File | Size | Purpose |\n",
    "|------|------|----------|\n",
    "| `checkpoint` | 77 bytes | Points to the latest checkpoint file |\n",
    "| `encoder.json` | ~1 MB | Token-to-ID mapping (vocabulary) |\n",
    "| `vocab.bpe` | ~446 KB | Byte-Pair Encoding merge rules |\n",
    "| `hparams.json` | 90 bytes | Model hyperparameters/configuration |\n",
    "| `model.ckpt.data-00000-of-00001` | ~475 MB | **Actual model weights** |\n",
    "| `model.ckpt.index` | ~5 KB | Index for weight tensors |\n",
    "| `model.ckpt.meta` | ~461 KB | TensorFlow graph metadata |\n",
    "\n",
    "Let's explore each file in detail!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134795f",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86069393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• GPT-2 model files not found. Downloading...\n",
      "  Downloading checkpoint... ‚úÖ\n",
      "  Downloading encoder.json... ‚úÖ\n",
      "  Downloading hparams.json... ‚úÖ\n",
      "  Downloading model.ckpt.data-00000-of-00001... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.ckpt.data-00000-of-00001: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 498M/498M [00:17<00:00, 29.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading model.ckpt.index... ‚úÖ\n",
      "  Downloading model.ckpt.meta... ‚úÖ\n",
      "  Downloading vocab.bpe... ‚úÖ\n",
      "\n",
      "‚úÖ Download complete!\n",
      "\n",
      "üìÇ Files in GPT-2 124M directory:\n",
      "--------------------------------------------------\n",
      "  checkpoint                                 77 bytes\n",
      "  encoder.json                              1017.9 KB\n",
      "  hparams.json                               90 bytes\n",
      "  model.ckpt.data-00000-of-00001             474.7 MB\n",
      "  model.ckpt.index                             5.1 KB\n",
      "  model.ckpt.meta                            460.1 KB\n",
      "  vocab.bpe                                  445.6 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress TensorFlow info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Path to GPT-2 model files\n",
    "MODEL_DIR = \"gpt2/124M\"\n",
    "\n",
    "# Check if we need to download the model files\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    print(\"üì• GPT-2 model files not found. Downloading...\")\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    \n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models/124M\"\n",
    "    filenames = [\n",
    "        \"checkpoint\",\n",
    "        \"encoder.json\",\n",
    "        \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\",\n",
    "        \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\",\n",
    "        \"vocab.bpe\"\n",
    "    ]\n",
    "    \n",
    "    for filename in filenames:\n",
    "        url = f\"{base_url}/{filename}\"\n",
    "        filepath = os.path.join(MODEL_DIR, filename)\n",
    "        \n",
    "        print(f\"  Downloading {filename}...\", end=\" \")\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            if total_size > 1024*1024:  # Show progress for large files\n",
    "                with tqdm(total=total_size, unit='B', unit_scale=True, desc=filename) as pbar:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "            else:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "                print(\"‚úÖ\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Download complete!\")\n",
    "\n",
    "# Display files in directory\n",
    "print(\"\\nüìÇ Files in GPT-2 124M directory:\")\n",
    "print(\"-\" * 50)\n",
    "for file in sorted(os.listdir(MODEL_DIR)):\n",
    "    size = os.path.getsize(os.path.join(MODEL_DIR, file))\n",
    "    if size > 1024*1024:\n",
    "        size_str = f\"{size/(1024*1024):.1f} MB\"\n",
    "    elif size > 1024:\n",
    "        size_str = f\"{size/1024:.1f} KB\"\n",
    "    else:\n",
    "        size_str = f\"{size} bytes\"\n",
    "    print(f\"  {file:40} {size_str:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d5d46",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ `hparams.json` - Model Configuration\n",
    "\n",
    "This file contains the **hyperparameters** that define the model architecture. It's the blueprint that tells us how big the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6116ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß GPT-2 124M Hyperparameters:\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"n_vocab\": 50257,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load and display hyperparameters\n",
    "with open(os.path.join(MODEL_DIR, \"hparams.json\"), \"r\") as f:\n",
    "    hparams = json.load(f)\n",
    "\n",
    "print(\"üîß GPT-2 124M Hyperparameters:\")\n",
    "print(\"-\" * 50)\n",
    "print(json.dumps(hparams, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b6e78",
   "metadata": {},
   "source": [
    "### Understanding Each Hyperparameter:\n",
    "\n",
    "| Parameter | Value | Meaning |\n",
    "|-----------|-------|----------|\n",
    "| `n_vocab` | 50257 | Size of vocabulary (number of unique tokens) |\n",
    "| `n_ctx` | 1024 | Maximum context length (tokens the model can \"see\") |\n",
    "| `n_embd` | 768 | Embedding dimension (size of each token's vector) |\n",
    "| `n_head` | 12 | Number of attention heads in multi-head attention |\n",
    "| `n_layer` | 12 | Number of transformer blocks (depth of the model) |\n",
    "\n",
    "### GPT-2 Model Sizes Comparison:\n",
    "\n",
    "| Model | Parameters | n_layer | n_head | n_embd |\n",
    "|-------|------------|---------|--------|--------|\n",
    "| 124M (Small) | 124 Million | 12 | 12 | 768 |\n",
    "| 355M (Medium) | 355 Million | 24 | 16 | 1024 |\n",
    "| 774M (Large) | 774 Million | 36 | 20 | 1280 |\n",
    "| 1558M (XL) | 1.5 Billion | 48 | 25 | 1600 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc16532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Parameter Count Breakdown:\n",
      "--------------------------------------------------\n",
      "Token Embeddings:          38,597,376 params\n",
      "Position Embeddings:          786,432 params\n",
      "Transformer Blocks:        84,971,520 params\n",
      "Final Layer Norm:               1,536 params\n",
      "--------------------------------------------------\n",
      "Total (approx):           124,356,864 params\n",
      "                      ~124 Million parameters\n"
     ]
    }
   ],
   "source": [
    "# Calculate approximate number of parameters\n",
    "n_vocab = hparams['n_vocab']\n",
    "n_ctx = hparams['n_ctx']\n",
    "n_embd = hparams['n_embd']\n",
    "n_head = hparams['n_head']\n",
    "n_layer = hparams['n_layer']\n",
    "\n",
    "# Token embeddings: n_vocab * n_embd\n",
    "token_emb_params = n_vocab * n_embd\n",
    "\n",
    "# Position embeddings: n_ctx * n_embd\n",
    "pos_emb_params = n_ctx * n_embd\n",
    "\n",
    "# Each transformer block has:\n",
    "# - Attention: 4 * n_embd * n_embd (Q, K, V, Output projections)\n",
    "# - MLP: 2 * n_embd * (4 * n_embd) = 8 * n_embd^2\n",
    "# - Layer norms: 4 * n_embd (2 layer norms with weight and bias)\n",
    "params_per_block = 4 * n_embd * n_embd + 8 * n_embd * n_embd + 4 * n_embd\n",
    "transformer_params = n_layer * params_per_block\n",
    "\n",
    "# Final layer norm\n",
    "final_ln_params = 2 * n_embd\n",
    "\n",
    "total_params = token_emb_params + pos_emb_params + transformer_params + final_ln_params\n",
    "\n",
    "print(\"üìä Parameter Count Breakdown:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Token Embeddings:     {token_emb_params:>15,} params\")\n",
    "print(f\"Position Embeddings:  {pos_emb_params:>15,} params\")\n",
    "print(f\"Transformer Blocks:   {transformer_params:>15,} params\")\n",
    "print(f\"Final Layer Norm:     {final_ln_params:>15,} params\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total (approx):       {total_params:>15,} params\")\n",
    "print(f\"                      ~{total_params/1e6:.0f} Million parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbf5b2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ `encoder.json` - Vocabulary Mapping\n",
    "\n",
    "This file contains the **token-to-ID mapping**. It maps each token (word piece) to a unique integer ID that the model uses internally.\n",
    "\n",
    "GPT-2 uses **Byte-Pair Encoding (BPE)** tokenization, which breaks words into subword units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9e26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Vocabulary Size: 50,257 tokens\n",
      "\n",
      "üî§ Sample tokens from vocabulary:\n",
      "--------------------------------------------------\n",
      "  Token: '!'                  ‚Üí ID: 0\n",
      "  Token: '\"'                  ‚Üí ID: 1\n",
      "  Token: '#'                  ‚Üí ID: 2\n",
      "  Token: '$'                  ‚Üí ID: 3\n",
      "  Token: '%'                  ‚Üí ID: 4\n",
      "  Token: '&'                  ‚Üí ID: 5\n",
      "  Token: \"'\"                  ‚Üí ID: 6\n",
      "  Token: '('                  ‚Üí ID: 7\n",
      "  Token: ')'                  ‚Üí ID: 8\n",
      "  Token: '*'                  ‚Üí ID: 9\n",
      "  Token: '+'                  ‚Üí ID: 10\n",
      "  Token: ','                  ‚Üí ID: 11\n",
      "  Token: '-'                  ‚Üí ID: 12\n",
      "  Token: '.'                  ‚Üí ID: 13\n",
      "  Token: '/'                  ‚Üí ID: 14\n",
      "  Token: '0'                  ‚Üí ID: 15\n",
      "  Token: '1'                  ‚Üí ID: 16\n",
      "  Token: '2'                  ‚Üí ID: 17\n",
      "  Token: '3'                  ‚Üí ID: 18\n",
      "  Token: '4'                  ‚Üí ID: 19\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder (vocabulary)\n",
    "with open(os.path.join(MODEL_DIR, \"encoder.json\"), \"r\") as f:\n",
    "    encoder = json.load(f)\n",
    "\n",
    "print(f\"üìñ Vocabulary Size: {len(encoder):,} tokens\")\n",
    "print(\"\\nüî§ Sample tokens from vocabulary:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Show some interesting tokens\n",
    "sample_tokens = list(encoder.items())[:20]\n",
    "for token, idx in sample_tokens:\n",
    "    # Make whitespace visible\n",
    "    display_token = repr(token)\n",
    "    print(f\"  Token: {display_token:20} ‚Üí ID: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95329e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Looking up specific tokens:\n",
      "--------------------------------------------------\n",
      "  'hello' ‚Üí ID: 31373\n",
      "  'Hello' ‚Üí ID: 15496\n",
      "  ' hello' ‚Üí NOT FOUND (would be split into subwords)\n",
      "  'world' ‚Üí ID: 6894\n",
      "  ' the' ‚Üí NOT FOUND (would be split into subwords)\n",
      "  'the' ‚Üí ID: 1169\n",
      "  'ƒ†the' ‚Üí ID: 262\n",
      "  'ing' ‚Üí ID: 278\n",
      "  'ƒ†ing' ‚Üí ID: 5347\n",
      "\n",
      "üí° Note: 'ƒ†' represents a space before the token (GPT-2's way of encoding spaces)\n"
     ]
    }
   ],
   "source": [
    "# Let's look at some specific tokens\n",
    "print(\"\\nüîç Looking up specific tokens:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "words_to_find = [\"hello\", \"Hello\", \" hello\", \"world\", \" the\", \"the\", \"ƒ†the\", \"ing\", \"ƒ†ing\"]\n",
    "\n",
    "for word in words_to_find:\n",
    "    if word in encoder:\n",
    "        print(f\"  '{word}' ‚Üí ID: {encoder[word]}\")\n",
    "    else:\n",
    "        print(f\"  '{word}' ‚Üí NOT FOUND (would be split into subwords)\")\n",
    "\n",
    "print(\"\\nüí° Note: 'ƒ†' represents a space before the token (GPT-2's way of encoding spaces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f24bc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Reverse lookup (ID ‚Üí Token):\n",
      "--------------------------------------------------\n",
      "  ID      0 ‚Üí Token: '!'\n",
      "  ID      1 ‚Üí Token: '\"'\n",
      "  ID    100 ‚Üí Token: '¬ß'\n",
      "  ID   1000 ‚Üí Token: 'ale'\n",
      "  ID  10000 ‚Üí Token: 'ƒ†pocket'\n",
      "  ID  50256 ‚Üí Token: '<|endoftext|>'\n",
      "\n",
      "üìù Special token: ID 50256 is '<|endoftext|>' - marks end of text\n"
     ]
    }
   ],
   "source": [
    "# Create reverse mapping (ID to token)\n",
    "decoder = {v: k for k, v in encoder.items()}\n",
    "\n",
    "print(\"\\nüîÑ Reverse lookup (ID ‚Üí Token):\")\n",
    "print(\"-\" * 50)\n",
    "for idx in [0, 1, 100, 1000, 10000, 50256]:\n",
    "    token = decoder.get(idx, \"NOT FOUND\")\n",
    "    print(f\"  ID {idx:>6} ‚Üí Token: {repr(token)}\")\n",
    "\n",
    "print(f\"\\nüìù Special token: ID 50256 is '<|endoftext|>' - marks end of text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8b4b3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ `vocab.bpe` - Byte-Pair Encoding Rules\n",
    "\n",
    "This file contains the **BPE merge rules**. BPE is a compression algorithm that iteratively merges the most frequent pairs of characters/tokens.\n",
    "\n",
    "### How BPE Works:\n",
    "1. Start with individual characters\n",
    "2. Find the most frequent pair of adjacent tokens\n",
    "3. Merge them into a new token\n",
    "4. Repeat until vocabulary size is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b120285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìú Total BPE merge rules: 50,000\n",
      "\n",
      "üîÄ First 20 merge rules (most common pairs):\n",
      "--------------------------------------------------\n",
      "  Rule   1: 'ƒ†' + 't' ‚Üí 'ƒ†t'\n",
      "  Rule   2: 'ƒ†' + 'a' ‚Üí 'ƒ†a'\n",
      "  Rule   3: 'h' + 'e' ‚Üí 'he'\n",
      "  Rule   4: 'i' + 'n' ‚Üí 'in'\n",
      "  Rule   5: 'r' + 'e' ‚Üí 're'\n",
      "  Rule   6: 'o' + 'n' ‚Üí 'on'\n",
      "  Rule   7: 'ƒ†t' + 'he' ‚Üí 'ƒ†the'\n",
      "  Rule   8: 'e' + 'r' ‚Üí 'er'\n",
      "  Rule   9: 'ƒ†' + 's' ‚Üí 'ƒ†s'\n",
      "  Rule  10: 'a' + 't' ‚Üí 'at'\n",
      "  Rule  11: 'ƒ†' + 'w' ‚Üí 'ƒ†w'\n",
      "  Rule  12: 'ƒ†' + 'o' ‚Üí 'ƒ†o'\n",
      "  Rule  13: 'e' + 'n' ‚Üí 'en'\n",
      "  Rule  14: 'ƒ†' + 'c' ‚Üí 'ƒ†c'\n",
      "  Rule  15: 'i' + 't' ‚Üí 'it'\n",
      "  Rule  16: 'i' + 's' ‚Üí 'is'\n",
      "  Rule  17: 'a' + 'n' ‚Üí 'an'\n",
      "  Rule  18: 'o' + 'r' ‚Üí 'or'\n",
      "  Rule  19: 'e' + 's' ‚Üí 'es'\n",
      "  Rule  20: 'ƒ†' + 'b' ‚Üí 'ƒ†b'\n"
     ]
    }
   ],
   "source": [
    "# Load BPE merge rules\n",
    "with open(os.path.join(MODEL_DIR, \"vocab.bpe\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    bpe_data = f.read()\n",
    "\n",
    "# Parse the BPE file\n",
    "bpe_lines = bpe_data.split('\\n')\n",
    "# First line is version, rest are merge rules\n",
    "bpe_merges = [tuple(line.split()) for line in bpe_lines[1:] if line.strip()]\n",
    "\n",
    "print(f\"üìú Total BPE merge rules: {len(bpe_merges):,}\")\n",
    "print(\"\\nüîÄ First 20 merge rules (most common pairs):\")\n",
    "print(\"-\" * 50)\n",
    "for i, (a, b) in enumerate(bpe_merges[:20]):\n",
    "    print(f\"  Rule {i+1:>3}: '{a}' + '{b}' ‚Üí '{a}{b}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9301e496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÄ Last 10 merge rules (least common pairs):\n",
      "--------------------------------------------------\n",
      "  Rule 49991: 'Comm' + 'ission' ‚Üí 'Commission'\n",
      "  Rule 49992: 'ƒ†(' + '/' ‚Üí 'ƒ†(/'\n",
      "  Rule 49993: '√¢ƒ¢¬¶' + '.\"' ‚Üí '√¢ƒ¢¬¶.\"'\n",
      "  Rule 49994: 'Com' + 'par' ‚Üí 'Compar'\n",
      "  Rule 49995: 'ƒ†ampl' + 'ification' ‚Üí 'ƒ†amplification'\n",
      "  Rule 49996: 'om' + 'inated' ‚Üí 'ominated'\n",
      "  Rule 49997: 'ƒ†reg' + 'ress' ‚Üí 'ƒ†regress'\n",
      "  Rule 49998: 'ƒ†Coll' + 'ider' ‚Üí 'ƒ†Collider'\n",
      "  Rule 49999: 'ƒ†inform' + 'ants' ‚Üí 'ƒ†informants'\n",
      "  Rule 50000: 'ƒ†g' + 'azed' ‚Üí 'ƒ†gazed'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÄ Last 10 merge rules (least common pairs):\")\n",
    "print(\"-\" * 50)\n",
    "for i, (a, b) in enumerate(bpe_merges[-10:]):\n",
    "    rule_num = len(bpe_merges) - 10 + i + 1\n",
    "    print(f\"  Rule {rule_num:>5}: '{a}' + '{b}' ‚Üí '{a}{b}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1dfba2",
   "metadata": {},
   "source": [
    "### Understanding BPE Merge Rules:\n",
    "\n",
    "The merge rules are ordered by frequency:\n",
    "- **Early rules** (like `'t' + 'h' ‚Üí 'th'`) are very common and applied first\n",
    "- **Later rules** create longer tokens from merged subwords\n",
    "\n",
    "This is why GPT-2 can handle any text - unknown words are broken into known subword pieces!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e5426",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ `checkpoint` - TensorFlow Checkpoint Pointer\n",
    "\n",
    "This small file simply points to the latest checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf25a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read checkpoint file\n",
    "with open(os.path.join(MODEL_DIR, \"checkpoint\"), \"r\") as f:\n",
    "    checkpoint_content = f.read()\n",
    "\n",
    "print(\"üìç Checkpoint file content:\")\n",
    "print(\"-\" * 50)\n",
    "print(checkpoint_content)\n",
    "\n",
    "print(\"\\nüí° This tells TensorFlow which checkpoint files to load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cbf962",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Model Checkpoint Files (The Actual Weights!)\n",
    "\n",
    "The three `model.ckpt.*` files together contain the **actual neural network weights**:\n",
    "\n",
    "| File | Purpose |\n",
    "|------|----------|\n",
    "| `model.ckpt.data-00000-of-00001` | Binary data containing all weight values |\n",
    "| `model.ckpt.index` | Index/map to locate tensors in the data file |\n",
    "| `model.ckpt.meta` | TensorFlow graph structure and metadata |\n",
    "\n",
    "Let's explore what's inside!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the checkpoint path\n",
    "ckpt_path = tf.train.latest_checkpoint(MODEL_DIR)\n",
    "print(f\"üìÇ Checkpoint path: {ckpt_path}\")\n",
    "\n",
    "# List all variables in the checkpoint\n",
    "print(\"\\nüì¶ All tensors in the checkpoint:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "variables = tf.train.list_variables(ckpt_path)\n",
    "total_params = 0\n",
    "\n",
    "for name, shape in variables:\n",
    "    num_params = np.prod(shape)\n",
    "    total_params += num_params\n",
    "    print(f\"{name:50} {str(shape):20} {num_params:>12,} params\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'TOTAL':50} {'':<20} {total_params:>12,} params\")\n",
    "print(f\"\\nüéØ Actual parameter count: {total_params:,} ({total_params/1e6:.1f}M)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6b81a",
   "metadata": {},
   "source": [
    "### Understanding the Weight Names:\n",
    "\n",
    "The naming convention follows this pattern:\n",
    "\n",
    "```\n",
    "model/\n",
    "‚îú‚îÄ‚îÄ wte          ‚Üí Word Token Embeddings (vocab_size √ó emb_dim)\n",
    "‚îú‚îÄ‚îÄ wpe          ‚Üí Word Position Embeddings (context_length √ó emb_dim)\n",
    "‚îú‚îÄ‚îÄ h0/          ‚Üí Transformer Block 0\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ln_1/    ‚Üí Layer Norm 1 (before attention)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ attn/    ‚Üí Multi-Head Attention\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ c_attn/  ‚Üí Combined Q, K, V projection\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ c_proj/  ‚Üí Output projection\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ln_2/    ‚Üí Layer Norm 2 (before MLP)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ mlp/     ‚Üí Feed-Forward Network\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ c_fc/    ‚Üí First linear layer (expand)\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ c_proj/  ‚Üí Second linear layer (project back)\n",
    "‚îú‚îÄ‚îÄ h1/ ... h11/ ‚Üí Transformer Blocks 1-11\n",
    "‚îî‚îÄ‚îÄ ln_f/        ‚Üí Final Layer Norm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load and examine specific weights\n",
    "print(\"üî¨ Examining specific weight tensors:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Token embeddings\n",
    "wte = tf.train.load_variable(ckpt_path, \"model/wte\")\n",
    "print(f\"\\n1Ô∏è‚É£ Token Embeddings (wte):\")\n",
    "print(f\"   Shape: {wte.shape} = (vocab_size, embedding_dim)\")\n",
    "print(f\"   This maps each of {wte.shape[0]:,} tokens to a {wte.shape[1]}-dimensional vector\")\n",
    "print(f\"   Sample embedding for token 0: {wte[0, :5]}... (first 5 values)\")\n",
    "\n",
    "# Position embeddings\n",
    "wpe = tf.train.load_variable(ckpt_path, \"model/wpe\")\n",
    "print(f\"\\n2Ô∏è‚É£ Position Embeddings (wpe):\")\n",
    "print(f\"   Shape: {wpe.shape} = (max_positions, embedding_dim)\")\n",
    "print(f\"   This encodes position information for up to {wpe.shape[0]} tokens\")\n",
    "print(f\"   Sample embedding for position 0: {wpe[0, :5]}... (first 5 values)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine attention weights from first transformer block\n",
    "print(\"\\n3Ô∏è‚É£ Attention Weights (Block 0):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# c_attn combines Q, K, V projections\n",
    "c_attn_w = tf.train.load_variable(ckpt_path, \"model/h0/attn/c_attn/w\")\n",
    "c_attn_b = tf.train.load_variable(ckpt_path, \"model/h0/attn/c_attn/b\")\n",
    "print(f\"   c_attn weight: {c_attn_w.shape}\")\n",
    "print(f\"   ‚Üí Combines Q, K, V projections: 768 ‚Üí 3√ó768 = 2304\")\n",
    "print(f\"   ‚Üí Each of the 12 heads gets 768/12 = 64 dimensions\")\n",
    "\n",
    "c_proj_w = tf.train.load_variable(ckpt_path, \"model/h0/attn/c_proj/w\")\n",
    "print(f\"   c_proj weight: {c_proj_w.shape}\")\n",
    "print(f\"   ‚Üí Projects concatenated heads back to embedding dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine MLP weights\n",
    "print(\"\\n4Ô∏è‚É£ MLP (Feed-Forward) Weights (Block 0):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "c_fc_w = tf.train.load_variable(ckpt_path, \"model/h0/mlp/c_fc/w\")\n",
    "c_proj_w = tf.train.load_variable(ckpt_path, \"model/h0/mlp/c_proj/w\")\n",
    "\n",
    "print(f\"   c_fc weight: {c_fc_w.shape}\")\n",
    "print(f\"   ‚Üí Expands: 768 ‚Üí 4√ó768 = 3072 (hidden dimension)\")\n",
    "print(f\"   c_proj weight: {c_proj_w.shape}\")\n",
    "print(f\"   ‚Üí Contracts: 3072 ‚Üí 768 (back to embedding dimension)\")\n",
    "print(f\"\\n   üí° The 4√ó expansion is a common design choice in transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f84972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine Layer Norm parameters\n",
    "print(\"\\n5Ô∏è‚É£ Layer Normalization Parameters:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ln1_g = tf.train.load_variable(ckpt_path, \"model/h0/ln_1/g\")\n",
    "ln1_b = tf.train.load_variable(ckpt_path, \"model/h0/ln_1/b\")\n",
    "print(f\"   ln_1 gamma (scale): {ln1_g.shape}\")\n",
    "print(f\"   ln_1 beta (shift):  {ln1_b.shape}\")\n",
    "\n",
    "ln_f_g = tf.train.load_variable(ckpt_path, \"model/ln_f/g\")\n",
    "ln_f_b = tf.train.load_variable(ckpt_path, \"model/ln_f/b\")\n",
    "print(f\"   ln_f (final) gamma: {ln_f_g.shape}\")\n",
    "print(f\"   ln_f (final) beta:  {ln_f_b.shape}\")\n",
    "print(f\"\\n   üí° Layer Norm has learnable scale (g) and shift (b) parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0908b3",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Loading All Weights into a Python Dictionary\n",
    "\n",
    "Now let's see how to load ALL the weights into a structured Python dictionary that can be used with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c892266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, hparams):\n",
    "    \"\"\"\n",
    "    Load GPT-2 parameters from TensorFlow checkpoint into a nested dictionary.\n",
    "    \n",
    "    The resulting structure:\n",
    "    {\n",
    "        'wte': array,           # Token embeddings\n",
    "        'wpe': array,           # Position embeddings\n",
    "        'blocks': [\n",
    "            {                   # Block 0\n",
    "                'ln_1': {'g': array, 'b': array},\n",
    "                'attn': {\n",
    "                    'c_attn': {'w': array, 'b': array},\n",
    "                    'c_proj': {'w': array, 'b': array}\n",
    "                },\n",
    "                'ln_2': {'g': array, 'b': array},\n",
    "                'mlp': {\n",
    "                    'c_fc': {'w': array, 'b': array},\n",
    "                    'c_proj': {'w': array, 'b': array}\n",
    "                }\n",
    "            },\n",
    "            ...                 # Blocks 1-11\n",
    "        ],\n",
    "        'ln_f': {'g': array, 'b': array}  # Final layer norm\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Initialize with empty blocks\n",
    "    params = {\"blocks\": [{} for _ in range(hparams[\"n_layer\"])]}\n",
    "    \n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "        \n",
    "        # Parse the variable name (skip 'model/' prefix)\n",
    "        variable_name_parts = name.split(\"/\")[1:]\n",
    "        \n",
    "        # Find target dictionary\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            # This is a transformer block parameter\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "            variable_name_parts = variable_name_parts[1:]\n",
    "        \n",
    "        # Navigate/create nested dictionaries\n",
    "        for key in variable_name_parts[:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "        \n",
    "        # Set the value\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "    \n",
    "    return params\n",
    "\n",
    "# Load all parameters\n",
    "print(\"‚è≥ Loading all GPT-2 weights...\")\n",
    "params = load_gpt2_params_from_tf_ckpt(ckpt_path, hparams)\n",
    "print(\"‚úÖ Weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f466a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the structure\n",
    "print(\"\\nüìä Loaded parameters structure:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def print_structure(d, indent=0):\n",
    "    \"\"\"Recursively print dictionary structure with array shapes\"\"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(\" \" * indent + f\"üìÅ {key}/\")\n",
    "            print_structure(value, indent + 4)\n",
    "        elif isinstance(value, list):\n",
    "            print(\" \" * indent + f\"üìÅ {key}/ [{len(value)} blocks]\")\n",
    "            # Just show first block structure\n",
    "            print(\" \" * (indent + 4) + \"üìÅ [0]/  (showing first block)\")\n",
    "            print_structure(value[0], indent + 8)\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(\" \" * indent + f\"üî¢ {key}: shape={value.shape}\")\n",
    "\n",
    "print_structure(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify we can access weights\n",
    "print(\"\\n‚úÖ Verification - Accessing loaded weights:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Token embeddings shape: {params['wte'].shape}\")\n",
    "print(f\"Position embeddings shape: {params['wpe'].shape}\")\n",
    "print(f\"Number of transformer blocks: {len(params['blocks'])}\")\n",
    "print(f\"Block 0 attention c_attn weight shape: {params['blocks'][0]['attn']['c_attn']['w'].shape}\")\n",
    "print(f\"Final layer norm gamma shape: {params['ln_f']['g'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa7b5de",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£ How Weights are Downloaded\n",
    "\n",
    "Let's understand the download process from `07. GPT-2_weights_download.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The download URLs\n",
    "base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "model_size = \"124M\"\n",
    "\n",
    "filenames = [\n",
    "    \"checkpoint\",\n",
    "    \"encoder.json\", \n",
    "    \"hparams.json\",\n",
    "    \"model.ckpt.data-00000-of-00001\",\n",
    "    \"model.ckpt.index\",\n",
    "    \"model.ckpt.meta\",\n",
    "    \"vocab.bpe\"\n",
    "]\n",
    "\n",
    "print(\"üåê GPT-2 Model Download URLs:\")\n",
    "print(\"=\" * 80)\n",
    "for filename in filenames:\n",
    "    url = f\"{base_url}/{model_size}/{filename}\"\n",
    "    print(f\"  {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbbf6b9",
   "metadata": {},
   "source": [
    "### Download Process:\n",
    "\n",
    "```python\n",
    "# 1. Create directory\n",
    "os.makedirs(\"gpt2/124M\", exist_ok=True)\n",
    "\n",
    "# 2. Download each file\n",
    "for filename in filenames:\n",
    "    url = f\"{base_url}/{model_size}/{filename}\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    \n",
    "    # Save to disk with progress bar\n",
    "    with open(f\"gpt2/124M/{filename}\", \"wb\") as f:\n",
    "        for chunk in response.iter_content(1024):\n",
    "            f.write(chunk)\n",
    "\n",
    "# 3. Load the TensorFlow checkpoint\n",
    "ckpt_path = tf.train.latest_checkpoint(\"gpt2/124M\")\n",
    "\n",
    "# 4. Extract weights into Python dictionary\n",
    "params = load_gpt2_params_from_tf_ckpt(ckpt_path, hparams)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4302fb82",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è‚É£ Using Weights with PyTorch\n",
    "\n",
    "Now let's see how these TensorFlow weights are converted and used in a PyTorch GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d881b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def assign_weights(pytorch_layer, params_dict, transpose_weights=True):\n",
    "    \"\"\"\n",
    "    Assign numpy weights to PyTorch layer.\n",
    "    \n",
    "    Note: TensorFlow uses (input_dim, output_dim) but PyTorch uses (output_dim, input_dim)\n",
    "    So we need to transpose the weight matrices!\n",
    "    \"\"\"\n",
    "    if 'w' in params_dict:\n",
    "        weight = params_dict['w']\n",
    "        if transpose_weights and len(weight.shape) == 2:\n",
    "            weight = weight.T  # Transpose for PyTorch\n",
    "        pytorch_layer.weight.data = torch.from_numpy(weight.copy())\n",
    "    \n",
    "    if 'b' in params_dict:\n",
    "        pytorch_layer.bias.data = torch.from_numpy(params_dict['b'].copy())\n",
    "\n",
    "print(\"üí° Key insight: TensorFlow vs PyTorch weight shapes\")\n",
    "print(\"=\" * 50)\n",
    "print(\"TensorFlow Linear: weight shape = (input_dim, output_dim)\")\n",
    "print(\"PyTorch Linear:    weight shape = (output_dim, input_dim)\")\n",
    "print(\"\\n‚Üí We must TRANSPOSE weights when converting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cece74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Loading token embeddings into PyTorch\n",
    "print(\"\\nüì• Loading token embeddings into PyTorch:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create PyTorch embedding layer\n",
    "token_embedding = nn.Embedding(hparams['n_vocab'], hparams['n_embd'])\n",
    "\n",
    "# Load weights (no transpose needed for embeddings)\n",
    "token_embedding.weight.data = torch.from_numpy(params['wte'].copy())\n",
    "\n",
    "print(f\"Original TF shape: {params['wte'].shape}\")\n",
    "print(f\"PyTorch layer shape: {token_embedding.weight.shape}\")\n",
    "print(f\"\\n‚úÖ Embedding loaded successfully!\")\n",
    "\n",
    "# Test it\n",
    "test_tokens = torch.tensor([50256, 0, 1])  # <|endoftext|> and first two tokens\n",
    "embeddings = token_embedding(test_tokens)\n",
    "print(f\"\\nTest embedding output shape: {embeddings.shape}\")\n",
    "print(f\"Embedding for token 0 (first 5 dims): {embeddings[1, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae59c4",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **`hparams.json`** - Contains model architecture configuration (layers, heads, dimensions)\n",
    "\n",
    "2. **`encoder.json`** - Maps tokens to integer IDs (50,257 tokens)\n",
    "\n",
    "3. **`vocab.bpe`** - Byte-Pair Encoding merge rules for tokenization\n",
    "\n",
    "4. **`checkpoint`** - Points to the checkpoint files\n",
    "\n",
    "5. **`model.ckpt.*`** - The actual neural network weights:\n",
    "   - Token embeddings: (50257, 768)\n",
    "   - Position embeddings: (1024, 768)\n",
    "   - 12 Transformer blocks with:\n",
    "     - Layer norms\n",
    "     - Multi-head attention (Q, K, V projections)\n",
    "     - Feed-forward MLP\n",
    "   - Final layer norm\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- GPT-2 124M has **124 million parameters**\n",
    "- Weights are stored in **TensorFlow checkpoint format**\n",
    "- Must **transpose** weights when loading into PyTorch\n",
    "- The architecture follows the standard transformer decoder pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3dc84",
   "metadata": {},
   "source": [
    "---\n",
    "## üîó Next Steps\n",
    "\n",
    "Now that you understand the GPT-2 weight files, you can:\n",
    "\n",
    "1. **Load weights into your own GPT-2 implementation** (from notebook 04)\n",
    "2. **Generate text** using the pre-trained model\n",
    "3. **Fine-tune** on your own dataset\n",
    "4. **Analyze** the learned representations\n",
    "\n",
    "See the next notebook for loading these weights into the GPT-2 model architecture!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
